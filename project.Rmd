---
title: "project"
output: html_document
authors: Yishan Zheng, Rindala Fayyad, Lauren Mock, Daniel Herrera, Yuning Liu, Jinyi Che
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
STEP 1

Simulate data
- fix n 
- Xi from a jointly Uniform distribution
- Noise from a normal distribution (mean = 0, variance = very small)
- Yi linear combination of the Xi's + noise (with fixed Betas)

```{r}
simulation <- function(n, d) {
  #set.seed(0)
  betas <- runif(d + 1, min = 0, max = 10)
  dat <- matrix(nrow = n, ncol = d + 1)
  dat <- as.data.frame(dat)
  e_vec <- rnorm(n, mean = 0, sd = 10)
  for (i in 1:n) {
    x_vec <- runif(d, min = 0, max = 100)
    y <- sum(betas[2 : length(betas)] * x_vec) + betas[1] + e_vec[i]
    row <- c(y, x_vec)
    dat[i,] <- row
  }
  colnames(dat)[1] <- "Y"
  lreg <- lm(Y ~ ., data = dat)
  estimate <- summary(lreg)$coeff[,1]
  return (estimate)
}


```


STEP 2

- Fit a linear regression model
- Get Beta estimators 

```{r}

```

Check Lab 10 simulation

REPEAT Step 1 and Step 2 100 times
Get expected value of the Beta estimators. 
Get Sample Variance of the Beta estimators. 
Get MSE (check for consistency)

For d = 1
```{r}
d = 1
n = 100
betas1 <- matrix(nrow = 1000, ncol = d + 1)
betas1 <- as.data.frame(betas1)

for (i in 1:1000){
  betas1[i,] <- simulation(n, d)
}

var1 <- matrix(nrow = 1, ncol = d + 1)
var1 <- as.data.frame(var1)

var1[,1] <- var(betas1[,1])
for (i in 1: d + 1){
  var1[,i] <- var(betas1[,i])
}

```


Repeat again with larger d
Do this until you reach a problem


For d = 50
```{r}
d = 50
n = 100
betas50 <- matrix(nrow = 1000, ncol = d + 1)
betas50 <- as.data.frame(betas50)

for (i in 1:1000){
  betas50[i,] <- simulation(n, d)
}

var50 <- matrix(nrow = 1, ncol = d + 1)
var50 <- as.data.frame(var50)

var50[,1] <- var(betas50[,1])
for (i in 1: d + 1){
  var50[,i] <- var(betas50[,i])
}

```

For d = 75
```{r}
d = 75
n = 100
betas75 <- matrix(nrow = 1000, ncol = d + 1)
betas75 <- as.data.frame(betas75)

for (i in 1:1000){
  betas75[i,] <- simulation(n, d)
}

var75 <- matrix(nrow = 1, ncol = d + 1)
var75 <- as.data.frame(var75)

var75[,1] <- var(betas75[,1])
for (i in 1: d + 1){
  var75[,i] <- var(betas75[,i])
}

```

For d = 97
```{r}
d = 97
n = 100
betas97 <- matrix(nrow = 1000, ncol = d + 1)
betas97 <- as.data.frame(betas97)

for (i in 1:1000){
  betas97[i,] <- simulation(n, d)
}

var97 <- matrix(nrow = 1, ncol = d + 1)
var97 <- as.data.frame(var97)

var97[,1] <- var(betas97[,1])
for (i in 1: d + 1){
  var97[,i] <- var(betas97[,i])
}

```

For d = 98
```{r}
d = 98
n = 100
betas98 <- matrix(nrow = 1000, ncol = d + 1)
betas98 <- as.data.frame(betas98)

for (i in 1:1000){
  betas98[i,] <- simulation(n, d)
}

var98 <- matrix(nrow = 1, ncol = d + 1)
var98 <- as.data.frame(var98)

var98[,1] <- var(betas98[,1])
for (i in 1: d + 1){
  var98[,i] <- var(betas98[,i])
}

```

For d = 99
```{r}
d = 99
n = 100
betas99 <- matrix(nrow = 1000, ncol = d + 1)
betas99 <- as.data.frame(betas99)

for (i in 1:1000){
  betas99[i,] <- simulation(n, d)
}

var99 <- matrix(nrow = 1, ncol = d + 1)
var99 <- as.data.frame(var99)

var99[,1] <- var(betas99[,1])
for (i in 1: d + 1){
  var99[,i] <- var(betas99[,i])
}

```

We notice that the MSE of the Beta estimates (which is equal to the Variance, since these estimates are unbiased by default (OLS estimators)) increases drastically when we set the number of parameters = n - 1. This shows that when the number of parameters is very close to the sample size, we lose consistency of the Beta estimators. When we set the number of parameters = n, our code crashes. 

```{r}
library(ggplot2)
library(dplyr)

MSE_beta1 <- c(var1[,2], var50[,2], var75[,2], var97[,2], var98[,2], var99[,2])
MSE_beta0 <- c(var1[,1], var50[,1], var75[,1], var97[,1], var98[,1], var99[,1])
MSE_beta26 <- c(NA, var50[,27], var75[,27], var97[,27], var98[,27], var99[,27])
nb <- c(1,50,75, 97, 98,99)
colors <- c("MSE Beta0" = "blue", "MSE Beta1" = "red", "MSE Beta26" = "orange")

temp <- data.frame(MSE = MSE_beta1, nb = nb)
temp %>% ggplot() +
  geom_point(aes(x = nb, y = MSE_beta1)) +
  geom_line(aes(x = nb, y = MSE_beta1, color = "MSE Beta1")) +
  geom_point(aes(x = nb, y = MSE_beta0))+
  geom_line(aes(x = nb, y = MSE_beta0, color = "MSE Beta0")) +
  geom_point(aes(x = nb, y = MSE_beta26)) +
  geom_line(aes(x = nb, y = MSE_beta26, color = "MSE Beta26")) +
  labs(x = "Number of Parameters", y = "MSE") + 
  ggtitle("n = 100")+
  scale_y_continuous(trans = "log10")+
  scale_color_manual(values = colors)+
  theme(legend.title = element_blank())

```

```{r}
#Excluding var99

MSE_beta1 <- c(var1[,2], var50[,2], var75[,2], var97[,2], var98[,2])
MSE_beta2 <- c(NA, var50[,3], var75[,3], var97[,3], var98[,3])
MSE_beta26 <- c(NA, var50[,27], var75[,27], var97[,27], var98[,27])
nb <- c(1,50,75, 97, 98)
colors <- c( "MSE Beta1" = "red", "MSE Beta26" = "orange", "MSE Beta2" = "green")

temp <- data.frame(MSE = MSE_beta1, nb = nb)
temp %>% ggplot() +
  geom_point(aes(x = nb, y = MSE_beta1)) +
  geom_line(aes(x = nb, y = MSE_beta1, color = "MSE Beta1")) +
  geom_point(aes(x = nb, y = MSE_beta2))+
  geom_line(aes(x = nb, y = MSE_beta2, color = "MSE Beta2")) +
  geom_point(aes(x = nb, y = MSE_beta26)) +
  geom_line(aes(x = nb, y = MSE_beta26, color = "MSE Beta26")) +
  labs(x = "Number of Parameters", y = "MSE") + 
  ggtitle("n = 100")+
  scale_color_manual(values = colors)+
  theme(legend.title = element_blank())+
  scale_x_continuous(breaks = c(0, 50, 75, 98))

```

